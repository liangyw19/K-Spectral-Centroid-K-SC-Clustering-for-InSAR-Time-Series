{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2d50321",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import pandas as pd\n",
    "import matplotlib.pylab as plt\n",
    "from math import sqrt\n",
    "import numpy as np \n",
    "from collections import defaultdict\n",
    "from numpy import linalg as LA\n",
    "from copy import deepcopy\n",
    "\n",
    "def cluster_time_series(t, c): \n",
    "    \"\"\"\n",
    "    Perform K-Spectral Centroid (K-SC) clustering on time series data.\n",
    "\n",
    "    Parameters:\n",
    "        t (ndarray): Time series data of shape (n_samples, n_timestamps)\n",
    "        c (int): Number of clusters (k)\n",
    "\n",
    "    Returns:\n",
    "        mem (ndarray): Cluster labels for each time series\n",
    "        mu (ndarray): Cluster centroids\n",
    "    \"\"\"\n",
    "    random.seed(0)\n",
    "    matrix = t\n",
    "    k = c\n",
    "    N = matrix.shape[0]\n",
    "    \n",
    "    # Randomly initialize cluster membership for each time series\n",
    "    mem = np.array([random.randint(0, k-1) for idx in range(N)])\n",
    "    \n",
    "    # Define alpha as in the original K-SC paper\n",
    "    alpha = lambda x, y: np.dot(x, y) / np.dot(y, y)\n",
    "    \n",
    "    # Define d^ (d_hat) as the shape-based distance\n",
    "    d_hat = lambda x, y: (np.linalg.norm(x - alpha(x, y) * y)) / (np.linalg.norm(x))\n",
    "    \n",
    "    for it in range(100):\n",
    "        print(\"Iteration\", it)  # Display the current iteration number\n",
    "        prev_mem = deepcopy(mem)\n",
    "        mu = np.zeros((k, matrix[0].shape[0]))  # Cluster centroids\n",
    "        \n",
    "        # Update centroids\n",
    "        for j in range(k):\n",
    "            A = []\n",
    "            for vec_idx in range(N): \n",
    "                if mem[vec_idx] == j: \n",
    "                    vec = matrix[vec_idx]\n",
    "                    A.append(vec)\n",
    "            A = np.array(A)\n",
    "            if A.shape[0] == 0: \n",
    "                mu[j] = np.zeros(matrix[0].shape[0])\n",
    "                continue\n",
    "            interm = np.sqrt(np.sum(np.square(A), axis=1))\n",
    "            B = np.divide(A, np.tile(interm, (A.shape[1], 1)).T)\n",
    "            M = np.matmul(B.T, B) - A.shape[0] * np.identity(A.shape[1])\n",
    "            w, v = LA.eig(M)\n",
    "            idx = np.argmin(np.abs(w))\n",
    "            mu[j] = -v[:, idx] if np.sum(v[:, idx]) < 0 else v[:, idx]\n",
    "\n",
    "        # Reassign time series to nearest centroid\n",
    "        for vec_idx in range(N): \n",
    "            vec = matrix[vec_idx]\n",
    "            distances = [d_hat(vec, mu[j]) for j in range(k)]\n",
    "            j_star = np.argmin(distances)\n",
    "            mem[vec_idx] = j_star\n",
    "            \n",
    "        # Stop if cluster assignments have not changed\n",
    "        if np.linalg.norm(prev_mem - mem) == 0: \n",
    "            break\n",
    "\n",
    "    # Optionally save results\n",
    "    # np.save('mu_' + str(k) + '.npy', mu)\n",
    "    # np.save('clusters_set_' + str(k) + '.npy', mem)\n",
    "\n",
    "    return mem, mu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a09bc8e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#read time series data\n",
    "time_series=pd.read_csv('time_series.csv',index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f020c799-8095-4123-b8b5-6875a8950ec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d181417b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#clustering time series\n",
    "defined_cluster=3\n",
    "x=np.array(time_series)\n",
    "labels,centers=cluster_time_series(x,defined_cluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc2ff7b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in centers:\n",
    "    plt.plot(i)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb0e5f4d-c143-4884-be53-b93b58b07e09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute silhouette scores\n",
    "import numpy as np\n",
    "\n",
    "# Define alpha and d_hat functions (extracted from your clustering code)\n",
    "def alpha(x, y):\n",
    "    return np.dot(x, y) / np.dot(y, y)\n",
    "\n",
    "def d_hat(x, y):\n",
    "    return np.linalg.norm(x - alpha(x, y) * y) / np.linalg.norm(x)\n",
    "\n",
    "def compute_silhouette_scores(x, labels):\n",
    "    \"\"\"\n",
    "    Compute silhouette scores using the custom distance metric d_hat.\n",
    "    \n",
    "    Parameters:\n",
    "        x: Original time series data, shape (n_samples, n_features)\n",
    "        labels: Cluster labels for each sample, shape (n_samples,)\n",
    "    \n",
    "    Returns:\n",
    "        mean_score: Mean silhouette score across all samples\n",
    "        s: Silhouette score for each sample\n",
    "    \"\"\"\n",
    "    n_samples = x.shape[0]\n",
    "    D = np.zeros((n_samples, n_samples))  # Pairwise distance matrix\n",
    "    \n",
    "    # Compute distances between all pairs of samples\n",
    "    for i in range(n_samples):\n",
    "        for j in range(n_samples):\n",
    "            D[i, j] = d_hat(x[i], x[j])\n",
    "    \n",
    "    a = np.zeros(n_samples)  # Mean intra-cluster distance\n",
    "    b = np.zeros(n_samples)  # Mean nearest-cluster distance\n",
    "    \n",
    "    for i in range(n_samples):\n",
    "        current_cluster = labels[i]\n",
    "        \n",
    "        # Compute a[i]: average distance to other samples in the same cluster\n",
    "        same_cluster = np.where(labels == current_cluster)[0]\n",
    "        same_cluster = same_cluster[same_cluster != i] \n",
    "        a[i] = np.mean(D[i, same_cluster]) if len(same_cluster) > 0 else 0\n",
    "        \n",
    "        # Compute b[i]: average distance to the nearest different cluster\n",
    "        other_clusters = np.unique(labels[labels != current_cluster])\n",
    "        b_list = []\n",
    "        for c in other_clusters:\n",
    "            cluster_samples = np.where(labels == c)[0]\n",
    "            if len(cluster_samples) == 0:\n",
    "                continue\n",
    "            b_list.append(np.mean(D[i, cluster_samples]))\n",
    "        \n",
    "        b[i] = np.min(b_list) if len(b_list) > 0 else 0\n",
    "    \n",
    "    \n",
    "    s = (b - a) / np.maximum(a, b)\n",
    "    \n",
    "    return np.mean(s), s\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a32c3b8-edf8-4f76-8af0-89366c9e5c53",
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_silhouette, silhouette_scores = compute_silhouette_scores(x, labels)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
